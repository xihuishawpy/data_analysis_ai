import streamlit as st
from zhipuai import ZhipuAI
import os
from dotenv import load_dotenv
import PyPDF2
import docx
import io
from typing import Optional, Dict, List
import json

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()
client = ZhipuAI(api_key=os.getenv("ZHIPUAI_API_KEY"))

def extract_text_from_pdf(pdf_file) -> str:
    """ä»PDFæ–‡ä»¶ä¸­æå–æ–‡æœ¬"""
    try:
        pdf_reader = PyPDF2.PdfReader(pdf_file)
        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text()
        return text
    except Exception as e:
        st.error(f"PDFæ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}")
        return ""

def extract_text_from_docx(docx_file) -> str:
    """ä»Wordæ–‡ä»¶ä¸­æå–æ–‡æœ¬"""
    try:
        doc = docx.Document(docx_file)
        text = ""
        for paragraph in doc.paragraphs:
            text += paragraph.text + "\n"
        return text
    except Exception as e:
        st.error(f"Wordæ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}")
        return ""

def analyze_resume(text: str, position: Optional[str] = None) -> str:
    """ä½¿ç”¨æ™ºè°±AIåˆ†æç®€å†å†…å®¹"""
    system_prompt = """
    #Role: Resume Analyst : ä¸“æ³¨äºä»ç®€å†ä¸­æå–å…³é”®ä¿¡æ¯ï¼Œå¹¶å°†å…¶è½¬åŒ–ä¸ºç»“æ„åŒ–æ•°æ®ã€‚
    ## Goals
    æå–ç®€å†ä¸­çš„æŠ€èƒ½ã€å·¥ä½œç»å†ã€æ•™è‚²èƒŒæ™¯å’Œé¡¹ç›®ç»å†ã€‚
    å°†æå–çš„ä¿¡æ¯è½¬åŒ–ä¸ºç»“æ„åŒ–æ•°æ®æ ¼å¼ã€‚
    ## Constrains
    å¿…é¡»ä¿æŒåŸå§‹ç®€å†å†…å®¹çš„å‡†ç¡®æ€§å’Œå®Œæ•´æ€§ã€‚
    ç»“æ„åŒ–æ•°æ®åº”æ¸…æ™°ã€æ˜“äºç†è§£å’Œæ£€ç´¢ã€‚
    ## Skills
    ç®€å†å†…å®¹åˆ†æèƒ½åŠ›
    æ•°æ®ç»“æ„åŒ–å¤„ç†èƒ½åŠ›
    ç²¾ç¡®çš„ä¿¡æ¯æå–å’Œæ€»ç»“èƒ½åŠ›
    ## Outputformat
    //ç»“æ„åŒ–æ•°æ®æ ¼å¼ï¼ŒåŒ…æ‹¬æ˜ç¡®çš„å­—æ®µå’Œç›¸åº”çš„ä¿¡æ¯ã€‚
    ## Workflow
    1.ä»”ç»†é˜…è¯»å¹¶åˆ†æç®€å†å†…å®¹ï¼š"ç®€å†å†…å®¹"ã€‚
    2.æå–å…³é”®ä¿¡æ¯ï¼ŒåŒ…æ‹¬æŠ€èƒ½ã€å·¥ä½œç»å†ã€æ•™è‚²èƒŒæ™¯å’Œé¡¹ç›®ç»å†ã€‚
    3.å°†æå–çš„ä¿¡æ¯æŒ‰ç…§é¢„å®šçš„ç»“æ„åŒ–æ•°æ®æ ¼å¼è¿›è¡Œç»„ç»‡ã€‚
    4.è¾“å‡ºç»“æ„åŒ–æ•°æ®ã€‚
    """
    
    user_prompt = f"""è¯·åˆ†æä»¥ä¸‹ç®€å†å†…å®¹ï¼Œç”Ÿæˆå€™é€‰äººç”»åƒï¼š
    
    ç›®æ ‡å²—ä½ï¼š{position if position else 'æœªæŒ‡å®š'}
    
    ç®€å†å†…å®¹ï¼š
    {text}
    """
    
    try:
        response = client.chat.completions.create(
            model="glm-4-flash",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.3,
            top_p=0.8,
            max_tokens=2000
        )
        return response.choices[0].message.content
    except Exception as e:
        st.error(f"ç®€å†åˆ†æå¤±è´¥: {str(e)}")
        return ""

def analyze_job_description(description: str) -> str:
    """åˆ†æå·¥ä½œå²—ä½è¦æ±‚"""
    system_prompt = """
    # Role: Job Description Analyst : åˆ†æå¹¶æå–å²—ä½æè¿°ä¸­çš„å…³é”®è¦æ±‚ï¼Œè½¬æ¢ä¸ºç»“æ„åŒ–æ ¼å¼
    ## Goals: ä»ç»™å®šçš„å²—ä½æè¿°ä¸­æå–å…³é”®è¦æ±‚ï¼ŒåŒ…æ‹¬æŠ€èƒ½è¦æ±‚ã€é¡¹ç›®ç»éªŒã€æœ€ä½å­¦å†ã€ç›¸å…³è¯ä¹¦å’Œèµ„æ ¼è®¤è¯ã€è¯­è¨€èƒ½åŠ›ç­‰ã€‚
    ## Constrains: å¿…é¡»éµå¾ªç»“æ„åŒ–æ ¼å¼ï¼Œç¡®ä¿ä¿¡æ¯å‡†ç¡®æ— è¯¯ã€‚
    ## Skills:
    ç²¾å‡†çš„ä¿¡æ¯æå–èƒ½åŠ›
    å¯¹å²—ä½æè¿°çš„æ·±å…¥ç†è§£
    å¿«é€Ÿå‡†ç¡®çš„æ•°æ®æ•´ç†èƒ½åŠ›
    ## Output Format:
    æŠ€èƒ½è¦æ±‚: åˆ—è¡¨æ ¼å¼
    é¡¹ç›®ç»éªŒ: å…·ä½“æè¿°æˆ–å¹´é™è¦æ±‚
    æœ€ä½å­¦å†: å­¦å†åç§°
    ç›¸å…³è¯ä¹¦å’Œèµ„æ ¼è®¤è¯: åˆ—è¡¨æ ¼å¼
    è¯­è¨€èƒ½åŠ›: è¯­è¨€åç§°åŠæ°´å¹³è¦æ±‚
    ## Workflow:
    è¯»å–å¹¶åˆ†æå²—ä½æè¿°æ–‡æœ¬ï¼šæ–‡æœ¬å†…å®¹"ã€‚
    æå–å…³é”®è¦æ±‚ï¼Œåˆ†ç±»æ•´ç†ã€‚
    æŒ‰ç…§æŒ‡å®šçš„ç»“æ„åŒ–æ ¼å¼è¾“å‡ºç»“æœã€‚
    """
    
    user_prompt = f"è¯·åˆ†æä»¥ä¸‹å·¥ä½œå²—ä½æè¿°ï¼Œå¹¶æå–å…³é”®è¦æ±‚ï¼š\n\n{description}"
    
    try:
        response = client.chat.completions.create(
            model="glm-4-flash",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.3,
            top_p=0.8,
            max_tokens=2500
        )
        return response.choices[0].message.content
    except Exception as e:
        st.error(f"å²—ä½åˆ†æå¤±è´¥: {str(e)}")
        return ""

def calculate_similarity(job_analysis: str, resume_analysis: str) -> str:
    """è®¡ç®—å²—ä½è¦æ±‚å’Œå€™é€‰äººç”»åƒçš„åŒ¹é…åº¦"""
    system_prompt = """
    # Goal è¯·åŸºäºä»¥ä¸‹å²—ä½å’Œå€™é€‰äººç”»åƒï¼Œè®¡ç®—è¯­ä¹‰ç›¸ä¼¼åº¦ï¼Œè¾“å‡ºå€™é€‰äººä¸å²—ä½çš„åŒ¹é…åº¦è¯„åˆ†ï¼ˆ0-100%ï¼‰ã€‚
    """
    
    user_prompt = f"""
    å²—ä½ç”»åƒï¼š
    {job_analysis}
    
    å€™é€‰äººç”»åƒï¼š
    {resume_analysis}
    """
    
    try:
        response = client.chat.completions.create(
            model="glm-4-flash",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.3,
            top_p=0.8,
            max_tokens=1500
        )
        return response.choices[0].message.content
    except Exception as e:
        st.error(f"åŒ¹é…åº¦è®¡ç®—å¤±è´¥: {str(e)}")
        return ""

def main():
    st.title("ğŸ“„ AIæ™ºèƒ½æ‹›è˜åŠ©æ‰‹")
    
    tab1, tab2, tab3 = st.tabs(["ç®€å†åˆ†æ", "å²—ä½åˆ†æ", "åŒ¹é…åº¦è®¡ç®—"])
    
    with tab1:
        st.header("ç®€å†åˆ†æ")
        uploaded_file = st.file_uploader("ä¸Šä¼ ç®€å†æ–‡ä»¶", type=['pdf', 'docx'])
        position = st.text_input("ç›®æ ‡å²—ä½ï¼ˆå¯é€‰ï¼‰", placeholder="ä¾‹å¦‚ï¼šPythonå¼€å‘å·¥ç¨‹å¸ˆ")
        
        if uploaded_file is not None:
            file_extension = uploaded_file.name.split('.')[-1].lower()
            resume_text = ""
            
            with st.spinner("æ­£åœ¨è¯»å–æ–‡ä»¶..."):
                if file_extension == 'pdf':
                    resume_text = extract_text_from_pdf(uploaded_file)
                elif file_extension == 'docx':
                    resume_text = extract_text_from_docx(uploaded_file)
            
            if resume_text:
                st.success("æ–‡ä»¶è¯»å–æˆåŠŸï¼")
                
                with st.expander("æŸ¥çœ‹æå–çš„æ–‡æœ¬å†…å®¹", expanded=False):
                    st.text(resume_text)
                
                if st.button("å¼€å§‹åˆ†æ", key="analyze_resume"):
                    with st.spinner("AIæ­£åœ¨åˆ†æç®€å†..."):
                        analysis = analyze_resume(resume_text, position)
                        if analysis:
                            st.session_state['resume_analysis'] = analysis
                            st.markdown(analysis)
            else:
                st.error("æ–‡ä»¶å†…å®¹æå–å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®ã€‚")
    
    with tab2:
        st.header("å²—ä½è¦æ±‚åˆ†æ")
        job_description = st.text_area(
            "è¯·è¾“å…¥å²—ä½æè¿°",
            height=200,
            placeholder="è¯·ç²˜è´´å®Œæ•´çš„èŒä½æè¿°..."
        )
        
        if st.button("åˆ†æå²—ä½è¦æ±‚", key="analyze_job"):
            if job_description:
                with st.spinner("æ­£åœ¨åˆ†æå²—ä½è¦æ±‚..."):
                    job_analysis = analyze_job_description(job_description)
                    if job_analysis:
                        st.markdown(job_analysis)
                        st.session_state['job_analysis'] = job_analysis
            else:
                st.warning("è¯·è¾“å…¥å²—ä½æè¿°")
    
    with tab3:
        st.header("åŒ¹é…åº¦è®¡ç®—")
        if 'job_analysis' not in st.session_state:
            st.warning("è¯·å…ˆåœ¨å²—ä½åˆ†ææ ‡ç­¾é¡µä¸­åˆ†æå²—ä½è¦æ±‚")
            return
            
        if 'resume_analysis' not in st.session_state:
            st.warning("è¯·å…ˆåœ¨ç®€å†åˆ†ææ ‡ç­¾é¡µä¸­åˆ†æå€™é€‰äººç®€å†")
            return
            
        if st.button("è®¡ç®—åŒ¹é…åº¦", key="calculate_match"):
            with st.spinner("æ­£åœ¨è®¡ç®—åŒ¹é…åº¦..."):
                match_result = calculate_similarity(
                    st.session_state['job_analysis'],
                    st.session_state['resume_analysis']
                )
                if match_result:
                    st.markdown(match_result)

if __name__ == "__main__":
    main()
